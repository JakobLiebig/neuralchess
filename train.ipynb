{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "import value_net\n",
    "\n",
    "data_dir = f'{os.getcwd()}/data'\n",
    "db_white_path = f'{data_dir}/train/white.txt'\n",
    "db_black_path = f'{data_dir}/train/black.txt'\n",
    "db_draw_path = f'{data_dir}/train/draw.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = value_net.Net()\n",
    "\n",
    "loss_history = []\n",
    "acc_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 256\n",
    "lr = .0001\n",
    "betas=(0.9, 0.99)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)\n",
    "\n",
    "sampler = value_net.Sampler(db_white_path, db_black_path, db_draw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0963331460952759, Acc: 0.3359375:   1%|          | 12/1000 [00:55<1:15:55,  4.61s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m t \u001b[38;5;241m=\u001b[39m tqdm\u001b[38;5;241m.\u001b[39mtrange(epochs)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m t:\n\u001b[0;32m---> 25\u001b[0m     loss, acc \u001b[38;5;241m=\u001b[39m \u001b[43mepoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     loss_history\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     27\u001b[0m     acc_history\u001b[38;5;241m.\u001b[39mappend(acc)\n",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m, in \u001b[0;36mepoch\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mepoch\u001b[39m(model):\n\u001b[1;32m      4\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m----> 6\u001b[0m     x, target \u001b[38;5;241m=\u001b[39m \u001b[43msampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen_uniform_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     y \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss_fn(y, target)\n",
      "File \u001b[0;32m~/Documents/Code/Python/neuralchess/value_net.py:94\u001b[0m, in \u001b[0;36mSampler.gen_uniform_sample\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m     91\u001b[0m black_size \u001b[38;5;241m=\u001b[39m size \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m     92\u001b[0m draw_size \u001b[38;5;241m=\u001b[39m size \u001b[38;5;241m-\u001b[39mwhite_size\u001b[38;5;241m-\u001b[39mblack_size\n\u001b[0;32m---> 94\u001b[0m white_fen_batch \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhite_db\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhite_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m white_x \u001b[38;5;241m=\u001b[39m Sampler\u001b[38;5;241m.\u001b[39mgen_tensor(white_fen_batch)\n\u001b[1;32m     96\u001b[0m white_label \u001b[38;5;241m=\u001b[39m Sampler\u001b[38;5;241m.\u001b[39mgen_label(\u001b[38;5;241m0\u001b[39m, white_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "def epoch(model):\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    x, target = sampler.gen_uniform_sample(batch_size)\n",
    "\n",
    "    y = model(x)\n",
    "    loss = loss_fn(y, target)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_labels = torch.argmax(y, -1)\n",
    "        t_labels = torch.argmax(target, -1)\n",
    "\n",
    "        correct_labels = torch.eq(y_labels, t_labels)\n",
    "        accuracy = correct_labels.sum() / correct_labels.numel()\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "t = tqdm.trange(epochs)\n",
    "for i in t:\n",
    "    loss, acc = epoch(model)\n",
    "    loss_history.append(loss)\n",
    "    acc_history.append(acc)\n",
    "\n",
    "    t.set_description(f'Loss: {loss}, Acc: {acc}')\n",
    "    t.refresh()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralchess-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
