{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "\n",
    "import value_net\n",
    "\n",
    "data_dir = f'{os.getcwd()}/data'\n",
    "db_white_path = f'{data_dir}/train/white.txt'\n",
    "db_black_path = f'{data_dir}/train/black.txt'\n",
    "db_draw_path = f'{data_dir}/train/draw.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = value_net.Net()\n",
    "\n",
    "loss_history = []\n",
    "acc_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 257\n",
    "lr = .0001\n",
    "betas=(0.9, 0.99)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_from_file(size, path):  \n",
    "    with open(path, 'r') as file:\n",
    "        db = file.read().split('\\n')\n",
    "    \n",
    "    fen_batch = np.random.choice(db, size=size, replace=False)\n",
    "    \n",
    "    fen_tensor_list = []\n",
    "    for fen in fen_batch:\n",
    "        fen_tensor_list.append(value_net.Encoder.from_fen(fen))\n",
    "    \n",
    "    return torch.stack(fen_tensor_list)\n",
    "    \n",
    "def gen_label(one_hot, size):\n",
    "    label = torch.zeros([1, 3])\n",
    "    label[0, one_hot] = 1.\n",
    "    label = label.repeat(size, 1)\n",
    "    \n",
    "    return label\n",
    "\n",
    "def gen_uniform_sample(batch_size):\n",
    "    # generates sample containing equal quantities of outcomes\n",
    "\n",
    "    sample_size = batch_size // 3\n",
    "    white_x = sample_from_file(sample_size, db_white_path)\n",
    "    white_label = gen_label(0, sample_size)\n",
    "\n",
    "    black_x = sample_from_file(sample_size, db_black_path)\n",
    "    black_label = gen_label(1, sample_size)\n",
    "\n",
    "    draw_x = sample_from_file(sample_size, db_draw_path)\n",
    "    draw_label = gen_label(2, sample_size)\n",
    "\n",
    "    x = torch.cat([white_x, black_x, draw_x], 0)\n",
    "    labels = torch.cat([white_label, black_label, draw_label], 0)\n",
    "\n",
    "    return x, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss: 1.0986889600753784, Acc: 0.3333333432674408: 100%|██████████| 2/2 [00:17<00:00,  8.70s/it]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "def epoch(model):\n",
    "    opt.zero_grad()\n",
    "    \n",
    "    x, target = gen_uniform_sample(batch_size)\n",
    "\n",
    "    y = model(x)\n",
    "    loss = loss_fn(y, target)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        y_labels = torch.argmax(y, -1)\n",
    "        t_labels = torch.argmax(target, -1)\n",
    "\n",
    "        correct_labels = torch.eq(y_labels, t_labels)\n",
    "        accuracy = correct_labels.sum() / correct_labels.numel()\n",
    "\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "\n",
    "    return loss.item(), accuracy.item()\n",
    "\n",
    "t = tqdm.trange(epochs)\n",
    "for i in t:\n",
    "    loss, acc = epoch(model)\n",
    "    loss_history.append(loss)\n",
    "    acc_history.append(acc)\n",
    "\n",
    "    t.set_description(f'Loss: {loss}, Acc: {acc}')\n",
    "    t.refresh()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuralchess-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
